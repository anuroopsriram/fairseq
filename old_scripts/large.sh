$ python train.py \
  --distributed-world-size 128 \
  --distributed-port $PORT /manifest/path \
  --save-dir /model/path \
  --fp16 \
  --num-workers 6 \
  --task audio_pretraining \
  --criterion wav2vec \
  --arch wav2vec2 \
  --log-keys '["prob_perplexity","code_perplexity","temp"]' \
  --quantize-targets --extractor-mode default \
  --conv-feature-layers '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] * 2' \
  --final-dim 768 \
  --latent-vars 320 \
  --latent-groups 2 \
  --latent-temp '(2.0,0.1,0.999995)' \
  --infonce \
  --optimizer adam \
  --adam-betas '(0.9,0.98)' \
  --adam-eps 1e-06 \
  --lr-scheduler polynomial_decay \
  --total-num-update 600000 \
  --lr 0.0003 \
  --warmup-updates 32000 \
  --mask-length 10 \
  --mask-prob 0.65 \
  --mask-selection static \
  --mask-other 0 \
  --encoder-layerdrop 0.0 \
  --dropout-input 0.1 \
  --dropout-features 0.1 \
  --feature-grad-mult 0.03 \
  --loss-weights '[0.1, 10]' \
  --conv-pos 128 \
  --conv-pos-groups 16 \
  --encoder-layers 24 \
  --encoder-embed-dim 1024 \
  --encoder-ffn-embed-dim 4096 \
  --encoder-attention-heads 16 \
  --num-negatives 100 \
  --cross-sample-negatives 0 \
  --max-sample-size 320000 \
  --min-sample-size 32000 \
  --dropout 0.0 \
  --attention-dropout 0.1 \
  --weight-decay 0.01 \
  --max-tokens 1200000 \
  --max-update 600000 \
  --skip-invalid-size-inputs-valid-test \
  --ddp-backend no_c10d \
